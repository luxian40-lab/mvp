"""
Asistente de IA H√çBRIDO: OpenAI (primero) ‚Üí Cohere (fallback)
"""
import logging
from django.conf import settings
import cohere
from .models import WhatsappLog, Estudiante

logger = logging.getLogger(__name__)

# ===== OPENAI =====
def get_openai_client():
    """Obtiene el cliente de OpenAI con la API key configurada"""
    try:
        from openai import OpenAI
        api_key = getattr(settings, 'OPENAI_API_KEY', None)
        if not api_key:
            raise ValueError("OPENAI_API_KEY no est√° configurada")
        return OpenAI(api_key=api_key)
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è No se pudo inicializar OpenAI: {e}")
        return None

# ===== COHERE (FALLBACK) =====
def get_cohere_client():
    """Obtiene el cliente de Cohere con la API key configurada"""
    api_key = getattr(settings, 'COHERE_API_KEY', None)
    if not api_key:
        raise ValueError("COHERE_API_KEY no est√° configurada en settings.py")
    return cohere.Client(api_key)

SYSTEM_PROMPT = """Eres un TUTOR EDUCATIVO y GU√çA AGR√çCOLA experto de Eki, una plataforma de educaci√≥n rural colombiana.

üéì TU ROL COMO TUTOR:
- Ense√±ar y explicar conceptos agr√≠colas paso a paso
- Guiar al campesino en su proceso de aprendizaje
- Hacer preguntas para evaluar comprensi√≥n
- Motivar y acompa√±ar en su desarrollo
- Corregir errores con paciencia y claridad

üå± TEMAS QUE ENSE√ëAS:
- Cultivos colombianos: pl√°tano hart√≥n, caf√©, cacao, yuca, aguacate
- T√©cnicas: siembra, riego, fertilizaci√≥n, control de plagas
- Ganader√≠a: manejo de ganado, pastos, salud animal
- Agricultura sostenible y buenas pr√°cticas
- Cosecha y poscosecha

‚ö†Ô∏è REGLA CR√çTICA SOBRE CURSOS:
- El estudiante tiene un CURSO ACTUAL que ver√°s en el contexto
- SIEMPRE contextualiza tus respuestas al curso actual del estudiante
- NO menciones otros cursos a menos que el estudiante pregunte expl√≠citamente
- Si pregunta sobre pl√°tano y est√° en caf√©, enf√≥cate en CAF√â
- Si pregunta algo general, relacionalo con su curso actual

üìö METODOLOG√çA DE ENSE√ëANZA:
1. Explica conceptos de forma sencilla (nivel campesino)
2. Usa ejemplos pr√°cticos del campo colombiano
3. Da consejos aplicables inmediatamente
4. Pregunta si entendi√≥ antes de avanzar
5. Relaciona con su experiencia previa
6. CONTEXTUALIZA todo al curso actual del estudiante

üí¨ ESTILO DE COMUNICACI√ìN:
- Amigable y cercano (como un maestro de confianza)
- Respuestas claras de 3-5 oraciones
- Usa emojis educativos: üìö üå± ‚úÖ üí° üéØ
- Lenguaje sencillo sin t√©rminos t√©cnicos complejos
- Haz preguntas gu√≠a: "¬øYa conoc√≠as esto?", "¬øQu√© te gustar√≠a aprender?"

üéØ OBJETIVO: No solo responder, sino ENSE√ëAR y GUIAR el aprendizaje del campesino en su curso actual

Contexto: Los estudiantes te escriben por WhatsApp buscando ayuda r√°pida sobre agricultura."""


def obtener_historial_conversacion(telefono: str, limite: int = 10):
    """
    Obtiene el historial reciente de conversaci√≥n con un estudiante.
    Estilo Huaku: memoria extendida + contexto del estudiante
    
    Args:
        telefono: N√∫mero del estudiante
        limite: Cantidad de mensajes a recuperar (por defecto 10 como Huaku)
    
    Returns:
        Lista de mensajes formateados para OpenAI con contexto
    """
    logs = WhatsappLog.objects.filter(
        telefono=telefono
    ).order_by('-fecha')[:limite * 2]  # Obtenemos m√°s para asegurar conversaci√≥n balanceada
    
    historial = []
    for log in reversed(logs):  # Orden cronol√≥gico
        if log.tipo == 'INCOMING':
            role = "user"
        elif log.tipo == 'SENT':
            role = "assistant"
        else:
            continue  # Skip si no es ninguno de los dos
        
        if log.mensaje:  # Solo agregar si hay mensaje
            historial.append({
                "role": role,
                "content": log.mensaje[:500]  # Limitar largo del mensaje
            })
    
    # Devolver solo los √∫ltimos 'limite' mensajes
    return historial[-limite:] if len(historial) > limite else historial


def responder_con_openai(mensaje: str, telefono: str, contexto_estudiante: str = "") -> str:
    """Intenta responder con OpenAI incluyendo historial de conversaci√≥n
    
    Implementaci√≥n estilo Huaku:
    - Memoria extendida (10 mensajes)
    - Contexto del progreso del estudiante
    - Personalizaci√≥n seg√∫n nivel
    """
    try:
        client = get_openai_client()
        if not client:
            raise ValueError("Cliente OpenAI no disponible")
        
        logger.info(f"ü§ñ Intentando con OpenAI para: {telefono}")
        
        # Obtener historial de conversaci√≥n (√∫ltimos 10 mensajes - estilo Huaku)
        historial = obtener_historial_conversacion(telefono, limite=10)
        
        # Construir mensajes para OpenAI
        mensajes = [
            {"role": "system", "content": SYSTEM_PROMPT + contexto_estudiante}
        ]
        
        # Agregar historial (excluyendo el mensaje actual que ya vendr√° al final)
        if historial:
            # Solo tomar los primeros 8 del historial para dejar espacio al mensaje actual
            mensajes.extend(historial[-8:])
        
        # Agregar el mensaje actual
        mensajes.append({"role": "user", "content": mensaje})
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=mensajes,
            temperature=0.7,
            max_tokens=200
        )
        
        respuesta = response.choices[0].message.content.strip()
        logger.info(f"‚úÖ OpenAI respondi√≥ con contexto: {respuesta[:50]}...")
        
        # Agregar opciones de navegaci√≥n
        respuesta_con_opciones = f"{respuesta}\n\n---\nüí¨ *Opciones:*\n‚Ä¢ Escribe *men√∫* para ver el men√∫ principal\n‚Ä¢ Escribe *continuar* para seguir con tu curso\n‚Ä¢ Escribe *ayuda* para ver todos los comandos"
        
        return respuesta_con_opciones
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è OpenAI fall√≥: {str(e)}")
        raise


def responder_con_cohere(mensaje: str, telefono: str, contexto_estudiante: str = "") -> str:
    """Responde con Cohere (fallback) incluyendo historial de conversaci√≥n
    
    Implementaci√≥n estilo Huaku: memoria extendida
    """
    try:
        logger.info(f"ü§ñ Usando Cohere (fallback) para: {telefono}")
        
        co = get_cohere_client()
        
        # Obtener historial de conversaci√≥n (10 mensajes)
        historial = obtener_historial_conversacion(telefono, limite=10)
        
        # Convertir historial a formato de Cohere (chat_history)
        chat_history = []
        for msg in historial[-8:]:  # √öltimos 8 mensajes (estilo Huaku)
            if msg["role"] == "user":
                chat_history.append({"role": "USER", "message": msg["content"]})
            elif msg["role"] == "assistant":
                chat_history.append({"role": "CHATBOT", "message": msg["content"]})
        
        response = co.chat(
            model='command-r-plus-08-2024',
            message=mensaje,
            chat_history=chat_history if chat_history else None,
            preamble=SYSTEM_PROMPT + contexto_estudiante,
            temperature=0.7,
            max_tokens=200
        )
        
        respuesta = response.text.strip()
        logger.info(f"‚úÖ Cohere respondi√≥ con contexto: {respuesta[:50]}...")
        
        # Agregar opciones de navegaci√≥n
        respuesta_con_opciones = f"{respuesta}\n\n---\nüí¨ *Opciones:*\n‚Ä¢ Escribe *men√∫* para ver el men√∫ principal\n‚Ä¢ Escribe *continuar* para seguir con tu curso\n‚Ä¢ Escribe *ayuda* para ver todos los comandos"
        
        return respuesta_con_opciones
        
    except Exception as e:
        logger.error(f"‚ùå Error en Cohere: {str(e)}", exc_info=True)
        raise


def responder_con_ia(mensaje: str, telefono: str) -> str:
    """
    Genera una respuesta inteligente usando IA H√çBRIDA.
    Intenta OpenAI primero, si falla usa Cohere.
    
    Args:
        mensaje: Mensaje del usuario
        telefono: N√∫mero de tel√©fono del usuario
    
    Returns:
        Respuesta generada por la IA
    """
    try:
        # Obtener informaci√≥n del estudiante si existe
        estudiante = None
        try:
            estudiante = Estudiante.objects.get(telefono=telefono)
        except Estudiante.DoesNotExist:
            pass
        
        # Construir contexto adicional con curso actual
        contexto_estudiante = ""
        if estudiante:
            contexto_estudiante = f"\nEstudiante: {estudiante.nombre}"
            
            # Obtener curso actual (m√°s reciente)
            from .models import ProgresoEstudiante
            progreso = ProgresoEstudiante.objects.filter(
                estudiante=estudiante
            ).order_by('-fecha_inicio').first()
            
            if progreso:
                porcentaje = progreso.porcentaje_avance()
                contexto_estudiante += f"\nCurso actual: {progreso.curso.nombre}"
                contexto_estudiante += f"\nProgreso: {porcentaje}%"
                if progreso.modulo_actual:
                    contexto_estudiante += f"\nM√≥dulo actual: {progreso.modulo_actual.titulo}"
                contexto_estudiante += f"\n\n‚ö†Ô∏è IMPORTANTE: El estudiante est√° aprendiendo sobre {progreso.curso.nombre}. Todas tus respuestas deben estar contextualizadas a este cultivo/tema espec√≠fico. NO menciones otros cursos a menos que el estudiante pregunte expl√≠citamente."
        
        # ESTRATEGIA H√çBRIDA: OpenAI ‚Üí Cohere
        try:
            # 1. Intentar con OpenAI primero
            return responder_con_openai(mensaje, telefono, contexto_estudiante)
        except:
            # 2. Si OpenAI falla, usar Cohere
            logger.info("üîÑ OpenAI no disponible, cambiando a Cohere...")
            return responder_con_cohere(mensaje, telefono, contexto_estudiante)
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"‚ùå Error en ambas IAs: {error_msg}", exc_info=True)
        print(f"‚ùå Error en IA: {error_msg}")
        
        # Fallback a respuestas b√°sicas
        from .intent_detector import detect_intent
        from .response_templates import get_response_for_intent
        
        intent = detect_intent(mensaje)
        fallback_response = get_response_for_intent(intent)
        
        logger.info(f"‚ö†Ô∏è Usando fallback para intent: {intent}")
        return fallback_response or "Disculpa, tengo problemas t√©cnicos. ¬øPuedes intentar m√°s tarde? üîß"


# ==========================================
# EVALUACI√ìN DE EX√ÅMENES CON IA
# ==========================================

def evaluar_respuesta_examen(pregunta_obj, respuesta_estudiante: str) -> dict:
    """
    Eval√∫a la respuesta de un estudiante a una pregunta de examen usando IA.
    
    Args:
        pregunta_obj: Objeto PreguntaExamen con la pregunta y respuesta correcta
        respuesta_estudiante: Texto de la respuesta del estudiante
    
    Returns:
        dict: {
            'puntaje': int (0-puntos_pregunta),
            'correcta': bool,
            'feedback': str
        }
    """
    try:
        # Intentar con OpenAI primero
        client = get_openai_client()
        if not client:
            raise ValueError("OpenAI no disponible")
        
        prompt_evaluacion = f"""Eres un tutor evaluando un examen agr√≠cola. Eval√∫a la siguiente respuesta:

PREGUNTA: {pregunta_obj.pregunta}

CONCEPTOS CLAVE ESPERADOS: {pregunta_obj.respuesta_correcta}

RESPUESTA DEL ESTUDIANTE: {respuesta_estudiante}

Eval√∫a si la respuesta contiene los conceptos clave y es coherente.
Responde EXACTAMENTE en este formato JSON:

{{
  "puntaje": [n√∫mero de 0 a {pregunta_obj.puntos}],
  "correcta": [true o false],
  "feedback": "[Breve retroalimentaci√≥n de 1-2 l√≠neas explicando por qu√© est√° bien o qu√© falt√≥]"
}}

NO agregues texto adicional, solo el JSON."""
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Eres un evaluador experto de ex√°menes agr√≠colas. Respondes SOLO con JSON v√°lido."},
                {"role": "user", "content": prompt_evaluacion}
            ],
            temperature=0.3,  # Baja temperatura para evaluaci√≥n consistente
            max_tokens=150
        )
        
        respuesta_ia = response.choices[0].message.content.strip()
        
        # Parsear JSON
        import json
        # Limpiar posibles markdown
        respuesta_ia = respuesta_ia.replace('```json', '').replace('```', '').strip()
        evaluacion = json.loads(respuesta_ia)
        
        logger.info(f"‚úÖ Evaluaci√≥n IA: {evaluacion['puntaje']}/{pregunta_obj.puntos} - {evaluacion['correcta']}")
        
        return evaluacion
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Error en evaluaci√≥n con OpenAI: {str(e)}, usando evaluaci√≥n b√°sica")
        
        # FALLBACK: Evaluaci√≥n b√°sica por palabras clave
        respuesta_lower = respuesta_estudiante.lower()
        palabras_clave = [k.strip().lower() for k in pregunta_obj.respuesta_correcta.split(',')]
        
        # Contar cu√°ntas palabras clave est√°n presentes
        coincidencias = sum(1 for palabra in palabras_clave if palabra in respuesta_lower)
        total_palabras = len(palabras_clave)
        
        # Calcular puntaje proporcional
        if coincidencias == 0:
            puntaje = 0
            correcta = False
            feedback = f"Tu respuesta no incluye los conceptos clave esperados. Repasa: {pregunta_obj.respuesta_correcta[:50]}..."
        elif coincidencias < total_palabras / 2:
            puntaje = int(pregunta_obj.puntos * 0.4)
            correcta = False
            feedback = f"Tu respuesta es parcial. Te falt√≥ mencionar algunos conceptos importantes."
        elif coincidencias < total_palabras:
            puntaje = int(pregunta_obj.puntos * 0.7)
            correcta = True
            feedback = f"Buena respuesta, aunque podr√≠as haber incluido m√°s detalles."
        else:
            puntaje = pregunta_obj.puntos
            correcta = True
            feedback = f"¬°Excelente! Tu respuesta incluye todos los conceptos clave."
        
        return {
            'puntaje': puntaje,
            'correcta': correcta,
            'feedback': feedback
        }


def procesar_examen_completo(estudiante, examen, respuestas_dict: dict) -> dict:
    """
    Procesa todas las respuestas de un examen y genera resultado final.
    
    Args:
        estudiante: Objeto Estudiante
        examen: Objeto Examen
        respuestas_dict: Dict con {numero_pregunta: respuesta_texto}
    
    Returns:
        dict: {
            'puntaje_total': int (0-100),
            'aprobado': bool,
            'feedback_general': str,
            'detalles_preguntas': list[dict]
        }
    """
    from .models import PreguntaExamen, ResultadoExamen
    
    preguntas = examen.preguntas.order_by('numero')
    puntaje_total = 0
    puntaje_maximo = sum(p.puntos for p in preguntas)
    detalles = []
    
    for pregunta in preguntas:
        numero = pregunta.numero
        respuesta_estudiante = respuestas_dict.get(numero, "")
        
        if not respuesta_estudiante:
            evaluacion = {
                'puntaje': 0,
                'correcta': False,
                'feedback': 'No respondiste esta pregunta.'
            }
        else:
            evaluacion = evaluar_respuesta_examen(pregunta, respuesta_estudiante)
        
        puntaje_total += evaluacion['puntaje']
        
        detalles.append({
            'numero': numero,
            'pregunta': pregunta.pregunta,
            'respuesta': respuesta_estudiante,
            'puntaje': evaluacion['puntaje'],
            'puntaje_maximo': pregunta.puntos,
            'correcta': evaluacion['correcta'],
            'feedback': evaluacion['feedback']
        })
    
    # Calcular puntaje en escala 0-100
    puntaje_porcentaje = int((puntaje_total / puntaje_maximo) * 100)
    aprobado = puntaje_porcentaje >= examen.puntaje_minimo
    
    # Generar feedback general
    if aprobado:
        if puntaje_porcentaje >= 90:
            feedback_general = f"üéâ ¬°EXCELENTE! Obtuviste {puntaje_porcentaje}%. Dominas muy bien este tema."
        elif puntaje_porcentaje >= 80:
            feedback_general = f"‚úÖ ¬°MUY BIEN! Obtuviste {puntaje_porcentaje}%. Buen desempe√±o."
        else:
            feedback_general = f"‚úÖ APROBADO con {puntaje_porcentaje}%. Sigue practicando para mejorar."
    else:
        feedback_general = f"‚ùå No aprobaste ({puntaje_porcentaje}%). Necesitas {examen.puntaje_minimo}% para aprobar. Repasa el curso y vuelve a intentarlo."
    
    # Guardar resultado en BD
    resultado, created = ResultadoExamen.objects.update_or_create(
        estudiante=estudiante,
        examen=examen,
        defaults={
            'puntaje': puntaje_porcentaje,
            'aprobado': aprobado,
            'respuestas': respuestas_dict,
            'feedback': feedback_general
        }
    )
    
    logger.info(f"üìä Examen procesado: {estudiante.nombre} - {puntaje_porcentaje}% - {'‚úÖ' if aprobado else '‚ùå'}")
    
    return {
        'puntaje_total': puntaje_porcentaje,
        'aprobado': aprobado,
        'feedback_general': feedback_general,
        'detalles_preguntas': detalles
    }
